{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOCR0v/qglKl5gwNJYSJJ6A"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 1: Install required libraries</h1>"
      ],
      "metadata": {
        "id": "RIuF39OSd-pS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch torch.nn torch.optim numpy scipy librosa pyaudio"
      ],
      "metadata": {
        "id": "HfYJ7eQyZvp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 2: Import required libraries</h1>"
      ],
      "metadata": {
        "id": "sxTNZ5UbeLyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import librosa\n",
        "import pyaudio\n",
        "import wave"
      ],
      "metadata": {
        "id": "QQwNfaZxb9jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 3: Load pre-trained LLM model and tokenizer</h1>"
      ],
      "metadata": {
        "id": "WytSXxCZeVGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=8)"
      ],
      "metadata": {
        "id": "02Leb742cBmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 4: Define a function to record audio input</h1>"
      ],
      "metadata": {
        "id": "Ymcdh6tHeaWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def record_audio(duration=5, sample_rate=22050):\n",
        "    print(\"Recording audio...\")\n",
        "    p = pyaudio.PyAudio()\n",
        "    stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)\n",
        "    frames = []\n",
        "    for i in range(0, int(sample_rate / 1024 * duration)):\n",
        "        data = stream.read(1024)\n",
        "        frames.append(data)\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "    return b''.join(frames)"
      ],
      "metadata": {
        "id": "6EzcL0zEdpV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 5: Define a function to preprocess audio input</h1>"
      ],
      "metadata": {
        "id": "Fm47dxZQehoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_audio(audio_data):\n",
        "    audio_data = np.frombuffer(audio_data, dtype=np.int16)\n",
        "    audio_data = librosa.resample(audio_data, orig_sr=22050, target_sr=16000)\n",
        "    audio_data = librosa.util.normalize(audio_data)\n",
        "    return audio_data"
      ],
      "metadata": {
        "id": "nZ2sS3uidpRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 6: Define a function to generate response</h1>"
      ],
      "metadata": {
        "id": "5oZ6d0Zleobx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(audio_data):\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        audio_data,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=1024,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "    outputs = model(inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
        "    logits = outputs.logits\n",
        "    response = torch.argmax(logits)\n",
        "    return response"
      ],
      "metadata": {
        "id": "ureCx3S2dpOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 7: Create a main function to integrate everything</h1>"
      ],
      "metadata": {
        "id": "P1bK0fCcevHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    while True:\n",
        "        audio_data = record_audio()\n",
        "        audio_data = preprocess_audio(audio_data)\n",
        "        response = generate_response(audio_data)\n",
        "        print(f\"Response: {response}\")"
      ],
      "metadata": {
        "id": "rkKusMiFdpK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Step 8: Run the main function</h1>"
      ],
      "metadata": {
        "id": "W32RhOxHe1p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "KwAbmqjBdpHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}